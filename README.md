<div align="center">
  <h2><b> [SIGKDD'25 PatchSTG] Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial Data Management Perspective
 </b></h2>
</div>

<div align="center">

[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/efficient-large-scale-traffic-forecasting/traffic-prediction-on-largest)](https://paperswithcode.com/sota/traffic-prediction-on-largest?p=efficient-large-scale-traffic-forecasting)
[![Arxiv link](https://img.shields.io/static/v1?label=arXiv&message=PatchSTG&color=red&logo=arxiv)](https://arxiv.org/abs/2412.09972)
![](https://img.shields.io/badge/PRs-Welcome-green)

</div>

<div align="center">

**[<a href="https://www.bilibili.com/video/BV1f5C3Y5Eb2/?spm_id_from=333.999.0.0&vd_source=ff21219783fd1e65d312b09da53b31c5">AITIME Talk</a>]**
**[<a href="https://mp.weixin.qq.com/s/M5w6I52tCIVsQXZ1ombVqA">æ—¶ç©ºæŽ¢ç´¢ä¹‹æ—…ä¸­æ–‡è§£è¯»</a>]**
**[<a href="https://zhuanlan.zhihu.com/p/14255424377">çŸ¥ä¹Žä¸­æ–‡è§£è¯»</a>]**

</div>

<div align="center">

<img src="./imgs/sketch.png" width="500">

</div>

---
>
> ðŸ™‹ Please let us know if you find out a mistake or have any suggestions!
> 
> ðŸŒŸ If you find this resource helpful, please consider to star this repository and cite our research:

```
@article{fang2024efficient,
  title={Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial Data Management Perspective},
  author={Fang, Yuchen and Liang, Yuxuan and Hui, Bo and Shao, Zezhi and Deng, Liwei and Liu, Xu and Jiang, Xinke and Zheng, Kai},
  journal={arXiv preprint arXiv:2412.09972},
  year={2024}
}
```

## Introduction
PatchSTG is an attention-based dynamic spatial modeling method that uses irregular spatial patching for efficient large-scale traffic forecasting.
Notably, we show that spatiotemporal graphs can be patched on the spatial dimension, effectively reducing complexity in attention.

<p align="center">
<img src="./imgs/frame.png" height = "300" alt="" align=center />
</p>

- PatchSTG comprises four components: (1) embedding the input traffic into high-dimensional representations with spatio-temporal properties, (2) segmenting the large-scale input into balanced and non-overlapped patches on the spatial dimension with irregularly distributed points, (3) using depth and breadth attentions on the patched input to capture local and global spatial dependencies efficiently, and (4) projecting representations to the predicted future traffic.

<p align="center">
<img src="./imgs/patching.png"  width="600" alt="" align=center />
</p>

## Hyper-parameters
- tps: temporal patch size
- tpn: temporal patch number ($tps\times tpn==input\_len$)
- recur: KDTree depth ($recur<\lfloor log_2(nodes)\rfloor$)
- sps: KDTree leaf size
- spn: KDTree nodes ($spn=2^{recur}$)
- factors: $sps\times factors$ is the spatial patch size and $spn/factors$ is the spatial patch number

## Requirements
- torch==1.11.0
- timm==1.0.12
- scikit_learn==1.0.2
- tqdm==4.67.1
- pandas==1.4.1
- numpy==1.22.3

## Folder Structure

```tex
â””â”€â”€ code-and-data
    â”œâ”€â”€ config                 # Including detail configurations
    â”œâ”€â”€ cpt                    # Storing pre-trained weight files (manually create the folder and download files)
    â”œâ”€â”€ data                   # Including traffic data (download), adj files (generated), and the meta data
    â”œâ”€â”€ lib
    â”‚   |â”€â”€  utils.py          # Codes of preprocessing datasets and calculating metrics
    â”œâ”€â”€ log                    # Storing log files
    â”œâ”€â”€ model
    â”‚   |â”€â”€  models.py         # The core source code of our PatchSTG
    â”œâ”€â”€ main.py                # This is the main file for training and testing
    â””â”€â”€ README.md              # This document
```

## Datasets
You can access the well pre-processed datasets from [[Google Drive]](https://drive.google.com/drive/folders/1BDH1C66BCKBe7ge8G-rBaj1j3p0iR0TC?usp=sharing), then place the downloaded contents under the correspond dataset folder such as `./data/SD`.

## PreTrained Weights
You can access the pretrained weights from [[Google Drive]](https://drive.google.com/drive/folders/1hFyV2C10P3wl3OJkNNhhHb2LTKXcJ2mO?usp=sharing), then place the downloaded contents under the constructed cpt folder `./cpt`.

## Quick Demos

### Using Pre-processed Datasets (NPZ format)

1. Download datasets and place them under `./data`
2. We provide pre-trained weights of results in the paper and the detail configurations under the folder `./config`. For example, you can test the SD dataset by:

```bash
python main.py --config ./config/SD.conf
```

3. If you want to train the model yourself, you can use the code at line 262 of the main file.

### Using ODPS Data (MaxCompute) ðŸ†•

We now support training directly from MaxCompute tables! This is useful for large-scale production scenarios.

#### Quick Start

1. **Set up ODPS credentials**:
```bash
export ALIBABA_CLOUD_ACCESS_KEY_ID="your_access_key_id"
export ALIBABA_CLOUD_ACCESS_KEY_SECRET="your_access_key_secret"
```

2. **Check environment**:
```bash
python quickstart_odps.py
```

3. **Edit configuration** `config/ODPS.conf`:
```ini
[data]
adcode = 110000           # City code (110000=Beijing, 310000=Shanghai, etc.)
start_date = 20250701     # Start date (YYYYMMDD)
end_date = 20250731       # End date (YYYYMMDD)

# Optional: Metadata table for spatial patching (recommended for best performance)
odps_meta_table = tb_inter_spatial_node_location
```

> ðŸ“– **About Metadata Table**: The metadata table contains geographic locations (lat/lng) of road segments, enabling KD-tree based spatial patching for better performance. See [META_TABLE_GUIDE.md](META_TABLE_GUIDE.md) for how to create it. If not provided, the model will use simple sequential patching.

4. **Check data quality** (recommended before training):
```bash
python check_odps_data.py --config config/ODPS.conf
```

5. **Start training**:
```bash
# Train only
python train_odps.py --config config/ODPS.conf --mode train

# Test only
python train_odps.py --config config/ODPS.conf --mode test

# Train and test
python train_odps.py --config config/ODPS.conf --mode both
```

#### Features

- âœ… Load data directly from MaxCompute tables
- âœ… Support filtering by city (adcode) and date range
- âœ… Automatic node discovery and dataset generation
- âœ… Built-in data quality checks
- âœ… Compatible with existing PatchSTG architecture

#### Documentation

- ðŸ“– [ODPS Training Guide](ODPS_TRAINING_GUIDE.md) - Complete guide for using ODPS data
- ðŸ“– [Meta Table Guide](META_TABLE_GUIDE.md) - How to create metadata table for spatial patching
- ðŸ“– [Data Loader README](DATA_LOADER_README.md) - Data loading architecture

#### City Codes

| City | Code |
|------|------|
| Beijing | 110000 |
| Shanghai | 310000 |
| Guangzhou | 440100 |
| Shenzhen | 440300 |
| Hangzhou | 330100 |
| Chengdu | 510100 |


## Further Reading
1, [**When Spatio-Temporal Meet Wavelets: Disentangled Traffic Forecasting via Efficient Spectral Graph Attention Networks**](https://ieeexplore.ieee.org/abstract/document/10184591), in *ICDE* 2023.
[\[GitHub Repo\]](https://github.com/LMissher/STWave)

**Authors**: Yuchen Fang, Yanjun Qin, Haiyong Luo, Fang Zhao, Bingbing Xu, Liang Zeng, Chenxing Wang.

```bibtex
@inproceedings{fang2023spatio,
  title={When spatio-temporal meet wavelets: Disentangled traffic forecasting via efficient spectral graph attention networks},
  author={Fang, Yuchen and Qin, Yanjun and Luo, Haiyong and Zhao, Fang and Xu, Bingbing and Zeng, Liang and Wang, Chenxing},
  booktitle={2023 IEEE 39th International Conference on Data Engineering (ICDE)},
  pages={517--529},
  year={2023}
}
```
