{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29142980",
   "metadata": {},
   "source": [
    "# æµ‹è¯•å¯†é›†æ•°æ®æ ¼å¼\n",
    "\n",
    "éªŒè¯æ–°çš„æ•°æ®åŠ è½½é€»è¾‘æ˜¯å¦ç”Ÿæˆäº†å¯†é›†æ ¼å¼çš„æ•°æ®\n",
    "\n",
    "**æµ‹è¯•ç›®æ ‡ï¼š**\n",
    "1. æ•°æ®å½¢çŠ¶æ­£ç¡®ï¼š`(samples, 12, num_nodes, 1)`\n",
    "2. æ•°æ®æ˜¯å¯†é›†çš„ï¼šæ¯ä¸ªæ ·æœ¬ > 50% èŠ‚ç‚¹æœ‰æ•°æ®\n",
    "3. æ²¡æœ‰ NaN/Inf å€¼\n",
    "4. ç©ºé—´ Patch åˆ›å»ºæˆåŠŸ\n",
    "5. æ ·æœ¬æ•°é‡åˆç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6d126",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "# æ£€æŸ¥ç¯å¢ƒå˜é‡\n",
    "if not os.getenv('ALIBABA_CLOUD_ACCESS_KEY_ID'):\n",
    "    print(\"âš ï¸  è¯·å…ˆè®¾ç½® ODPS ç¯å¢ƒå˜é‡:\")\n",
    "    print(\"  export ALIBABA_CLOUD_ACCESS_KEY_ID='...'\")\n",
    "    print(\"  export ALIBABA_CLOUD_ACCESS_KEY_SECRET='...'\")\n",
    "else:\n",
    "    print(\"âœ… ODPS å‡­è¯å·²è®¾ç½®\")\n",
    "\n",
    "from lib.odps_data_loader import ODPSDataLoader\n",
    "from lib.utils import log_string\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ§ª æµ‹è¯•æ–°çš„æ•°æ®åŠ è½½é€»è¾‘ï¼ˆå¯†é›†æ ¼å¼ï¼‰\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb42c8",
   "metadata": {},
   "source": [
    "## 2. é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a65adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ—¥å¿—ç›®å½•\n",
    "os.makedirs('./log', exist_ok=True)\n",
    "log = open('./log/test_data_loader.log', 'w')\n",
    "\n",
    "# é…ç½®\n",
    "config = {\n",
    "    'odps_project': 'autonavi_traffic_report',\n",
    "    'odps_endpoint': 'http://service-corp.odps.aliyun-inc.com/api',\n",
    "    'odps_table': 'tb_inter_spatial_method_pretrain_data',\n",
    "    'odps_meta_table': 'intersection_meta_aligned',\n",
    "    'adcode': '650100',\n",
    "    'start_date': '20250919',\n",
    "    'end_date': '20250919',  # åªæµ‹è¯•1å¤©æ•°æ®\n",
    "    'limit': 1000,  # ğŸ”¥ é™åˆ¶1000æ¡è®°å½•ç”¨äºå¿«é€Ÿæµ‹è¯•\n",
    "    'input_len': 12,\n",
    "    'output_len': 12,\n",
    "    'train_ratio': 0.6,\n",
    "    'val_ratio': 0.2,\n",
    "    'test_ratio': 0.2,\n",
    "    'recur_times': 1,\n",
    "    'spa_patchsize': 4\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“‹ é…ç½®:\")\n",
    "print(f\"  åŸå¸‚: {config['adcode']} (ä¹Œé²æœ¨é½)\")\n",
    "print(f\"  æ—¥æœŸ: {config['start_date']} ~ {config['end_date']}\")\n",
    "print(f\"  âš¡ æ•°æ®é™åˆ¶: {config['limit']} æ¡è®°å½•ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰\")\n",
    "print(f\"  è¾“å…¥é•¿åº¦: {config['input_len']}\")\n",
    "print(f\"  è¾“å‡ºé•¿åº¦: {config['output_len']}\")\n",
    "print(f\"  æ•°æ®åˆ’åˆ†: {config['train_ratio']:.0%} / {config['val_ratio']:.0%} / {config['test_ratio']:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8c5993",
   "metadata": {},
   "source": [
    "## 3. åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d26f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š åŠ è½½æ•°æ®...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    loader = ODPSDataLoader(config, log)\n",
    "    loader.load_data()\n",
    "    \n",
    "    print(\"\\nâœ… æ•°æ®åŠ è½½æˆåŠŸï¼\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æ•°æ®åŠ è½½å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    log.close()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203c636",
   "metadata": {},
   "source": [
    "## 4. è·å–æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–æ•°æ®\n",
    "trainX, trainY, trainXTE, trainYTE = loader.get_train_data()\n",
    "valX, valY, valXTE, valYTE = loader.get_val_data()\n",
    "testX, testY, testXTE, testYTE = loader.get_test_data()\n",
    "mean, std = loader.get_normalization_params()\n",
    "\n",
    "print(\"âœ… æ•°æ®é›†è·å–æˆåŠŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae10b2",
   "metadata": {},
   "source": [
    "## 5. éªŒè¯æ•°æ®å½¢çŠ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22bb94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“ æ•°æ®å½¢çŠ¶éªŒè¯\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nè®­ç»ƒé›†:\")\n",
    "print(f\"  X shape: {trainX.shape}\")\n",
    "print(f\"  Y shape: {trainY.shape}\")\n",
    "print(f\"  TE shape: {trainXTE.shape}\")\n",
    "print(f\"  æœŸæœ›: (samples, 12, {loader.node_num}, 1)\")\n",
    "\n",
    "print(f\"\\néªŒè¯é›†:\")\n",
    "print(f\"  X shape: {valX.shape}\")\n",
    "print(f\"  Y shape: {valY.shape}\")\n",
    "\n",
    "print(f\"\\næµ‹è¯•é›†:\")\n",
    "print(f\"  X shape: {testX.shape}\")\n",
    "print(f\"  Y shape: {testY.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82727d9",
   "metadata": {},
   "source": [
    "## 6. å¯†é›†æ€§éªŒè¯ï¼ˆå…³é”®æµ‹è¯•ï¼ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ” å¯†é›†æ€§éªŒè¯ï¼ˆå…³é”®ï¼‰\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# æ£€æŸ¥æ¯ä¸ªæ ·æœ¬æœ‰å¤šå°‘èŠ‚ç‚¹æœ‰éé›¶å€¼\n",
    "def check_density(X, name):\n",
    "    print(f\"\\n{name}:\")\n",
    "    # å¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œç»Ÿè®¡æœ‰å¤šå°‘èŠ‚ç‚¹åœ¨ä»»æ„æ—¶é—´æ­¥æœ‰éé›¶å€¼\n",
    "    nodes_with_data = []\n",
    "    for i in range(min(5, len(X))):  # æ£€æŸ¥å‰5ä¸ªæ ·æœ¬\n",
    "        # X[i]: (T, N, 1)\n",
    "        has_data = (X[i, :, :, 0] > 0).any(axis=0)  # (N,) - æ¯ä¸ªèŠ‚ç‚¹æ˜¯å¦æœ‰æ•°æ®\n",
    "        num_nodes = has_data.sum()\n",
    "        nodes_with_data.append(num_nodes)\n",
    "        \n",
    "        if i < 3:  # è¯¦ç»†æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬\n",
    "            print(f\"  æ ·æœ¬ {i}: {num_nodes}/{loader.node_num} ä¸ªèŠ‚ç‚¹æœ‰æ•°æ® ({num_nodes/loader.node_num*100:.1f}%)\")\n",
    "            \n",
    "            # æ˜¾ç¤ºæ ·æœ¬çš„æµé‡èŒƒå›´\n",
    "            sample_data = X[i, :, :, 0]\n",
    "            non_zero = sample_data[sample_data > 0]\n",
    "            if len(non_zero) > 0:\n",
    "                print(f\"         æµé‡èŒƒå›´: [{non_zero.min():.2f}, {non_zero.max():.2f}]\")\n",
    "    \n",
    "    avg_nodes = np.mean(nodes_with_data)\n",
    "    min_nodes = np.min(nodes_with_data)\n",
    "    max_nodes = np.max(nodes_with_data)\n",
    "    \n",
    "    print(f\"  å¹³å‡: {avg_nodes:.1f} ä¸ªèŠ‚ç‚¹æœ‰æ•°æ® ({avg_nodes/loader.node_num*100:.1f}%)\")\n",
    "    print(f\"  èŒƒå›´: [{min_nodes}, {max_nodes}]\")\n",
    "    \n",
    "    # åˆ¤æ–­æ˜¯å¦å¯†é›†\n",
    "    if avg_nodes / loader.node_num > 0.5:\n",
    "        print(f\"  âœ… æ•°æ®æ˜¯å¯†é›†çš„ï¼ˆ> 50% èŠ‚ç‚¹æœ‰æ•°æ®ï¼‰\")\n",
    "        return True\n",
    "    elif avg_nodes / loader.node_num > 0.1:\n",
    "        print(f\"  âš ï¸  æ•°æ®ç¨€ç–åº¦ä¸­ç­‰ï¼ˆ10-50% èŠ‚ç‚¹æœ‰æ•°æ®ï¼‰\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"  âŒ æ•°æ®æ˜¯ç¨€ç–çš„ï¼ˆ< 10% èŠ‚ç‚¹æœ‰æ•°æ®ï¼‰\")\n",
    "        return False\n",
    "\n",
    "is_dense_train = check_density(trainX, \"è®­ç»ƒé›†\")\n",
    "is_dense_val = check_density(valX, \"éªŒè¯é›†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef3a44",
   "metadata": {},
   "source": [
    "## 7. æ•°æ®ç»Ÿè®¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š æ•°æ®ç»Ÿè®¡\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\næµé‡å€¼ç»Ÿè®¡:\")\n",
    "print(f\"  è®­ç»ƒé›†èŒƒå›´: [{trainX.min():.2f}, {trainX.max():.2f}]\")\n",
    "print(f\"  éªŒè¯é›†èŒƒå›´: [{valX.min():.2f}, {valX.max():.2f}]\")\n",
    "print(f\"  æµ‹è¯•é›†èŒƒå›´: [{testX.min():.2f}, {testX.max():.2f}]\")\n",
    "\n",
    "print(f\"\\nå½’ä¸€åŒ–å‚æ•°:\")\n",
    "print(f\"  Mean: {mean:.4f}\")\n",
    "print(f\"  Std: {std:.4f}\")\n",
    "\n",
    "# éé›¶å€¼æ¯”ä¾‹\n",
    "train_nonzero_ratio = (trainX > 0).sum() / trainX.size * 100\n",
    "val_nonzero_ratio = (valX > 0).sum() / valX.size * 100\n",
    "\n",
    "print(f\"\\néé›¶å€¼æ¯”ä¾‹:\")\n",
    "print(f\"  è®­ç»ƒé›†: {train_nonzero_ratio:.2f}%\")\n",
    "print(f\"  éªŒè¯é›†: {val_nonzero_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd05a7a",
   "metadata": {},
   "source": [
    "## 8. æ—¶é—´ç‰¹å¾éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da506db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"â° æ—¶é—´ç‰¹å¾éªŒè¯\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nå‰3ä¸ªæ ·æœ¬çš„æ—¶é—´ç‰¹å¾:\")\n",
    "for i in range(min(3, len(trainXTE))):\n",
    "    te = trainXTE[i]\n",
    "    print(f\"\\næ ·æœ¬ {i}:\")\n",
    "    print(f\"  è¾“å…¥æ—¶é—´æ­¥ 0: tod={te[0,0]:.3f}, dow={te[0,1]:.3f}\")\n",
    "    print(f\"  è¾“å…¥æ—¶é—´æ­¥ 11: tod={te[11,0]:.3f}, dow={te[11,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9be92",
   "metadata": {},
   "source": [
    "## 9. ç©ºé—´ Patch éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3579e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸŒ³ ç©ºé—´ Patch éªŒè¯\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ori_parts, reo_parts, reo_all = loader.get_patch_indices()\n",
    "\n",
    "if ori_parts is not None:\n",
    "    print(f\"  Patch æ•°é‡: {len(ori_parts)}\")\n",
    "    patch_sizes = [len(p) for p in ori_parts]\n",
    "    print(f\"  Patch å¤§å°èŒƒå›´: [{min(patch_sizes)}, {max(patch_sizes)}]\")\n",
    "    print(f\"  å¹³å‡ Patch å¤§å°: {np.mean(patch_sizes):.1f}\")\n",
    "    print(f\"  âœ… ç©ºé—´ patch åˆ›å»ºæˆåŠŸ\")\n",
    "else:\n",
    "    print(f\"  âŒ æœªåˆ›å»ºç©ºé—´ patch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad65a51",
   "metadata": {},
   "source": [
    "## 10. æœ€ç»ˆåˆ¤å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229749dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… æµ‹è¯•ç»“æœ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "success = True\n",
    "issues = []\n",
    "\n",
    "# 1. å½¢çŠ¶æ£€æŸ¥\n",
    "if trainX.shape[1:] != (12, loader.node_num, 1):\n",
    "    success = False\n",
    "    issues.append(f\"âŒ è®­ç»ƒé›†å½¢çŠ¶é”™è¯¯: {trainX.shape}\")\n",
    "else:\n",
    "    print(\"âœ… æ•°æ®å½¢çŠ¶æ­£ç¡®\")\n",
    "\n",
    "# 2. å¯†é›†æ€§æ£€æŸ¥\n",
    "if not is_dense_train:\n",
    "    success = False\n",
    "    issues.append(\"âŒ æ•°æ®ä»ç„¶æ˜¯ç¨€ç–çš„ï¼ˆæ¯ä¸ªæ ·æœ¬åªæœ‰å°‘æ•°èŠ‚ç‚¹æœ‰å€¼ï¼‰\")\n",
    "else:\n",
    "    print(\"âœ… æ•°æ®æ˜¯å¯†é›†çš„ï¼ˆæ¯ä¸ªæ ·æœ¬åŒ…å«å¤§éƒ¨åˆ†èŠ‚ç‚¹ï¼‰\")\n",
    "\n",
    "# 3. æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥\n",
    "if np.any(np.isnan(trainX)) or np.any(np.isinf(trainX)):\n",
    "    success = False\n",
    "    issues.append(\"âŒ æ•°æ®åŒ…å« NaN æˆ– Inf\")\n",
    "else:\n",
    "    print(\"âœ… æ•°æ®æ—  NaN/Inf\")\n",
    "\n",
    "# 4. æ ·æœ¬æ•°é‡åˆç†æ€§\n",
    "expected_samples = 1440 - 12 - 12 + 1  # 1å¤©1440åˆ†é’Ÿ\n",
    "actual_total = len(trainX) + len(valX) + len(testX)\n",
    "if abs(actual_total - expected_samples) > 10:\n",
    "    print(f\"âš ï¸  æ ·æœ¬æ•°é‡å¼‚å¸¸: æœŸæœ›çº¦{expected_samples}ï¼Œå®é™…{actual_total}\")\n",
    "else:\n",
    "    print(f\"âœ… æ ·æœ¬æ•°é‡åˆç†: {actual_total}\")\n",
    "\n",
    "# 5. Patch æ£€æŸ¥\n",
    "if ori_parts is None:\n",
    "    success = False\n",
    "    issues.append(\"âŒ æœªåˆ›å»ºç©ºé—´ patch\")\n",
    "else:\n",
    "    print(\"âœ… ç©ºé—´ patch å·²åˆ›å»º\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if success:\n",
    "    print(\"ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒã€‚\")\n",
    "else:\n",
    "    print(\"âš ï¸  å­˜åœ¨é—®é¢˜:\")\n",
    "    for issue in issues:\n",
    "        print(f\"  {issue}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "log.close()\n",
    "\n",
    "print(f\"\\nè¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: ./log/test_data_loader.log\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
