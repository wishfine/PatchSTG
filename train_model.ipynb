{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd66e41",
   "metadata": {},
   "source": [
    "# PatchSTG æ¨¡å‹è®­ç»ƒ Notebook\n",
    "\n",
    "ä½¿ç”¨ ODPS æ•°æ®è®­ç»ƒ PatchSTG äº¤é€šæµé‡é¢„æµ‹æ¨¡å‹\n",
    "\n",
    "**é…ç½®ä¿¡æ¯ï¼š**\n",
    "- åŸå¸‚ï¼šåŒ—äº¬ (adcode = 110000)\n",
    "- æ—¥æœŸï¼š2025-09-19 ~ 2025-09-25 (7å¤©)\n",
    "- æ•°æ®åˆ’åˆ†ï¼š60% / 20% / 20%\n",
    "- è¾“å…¥é•¿åº¦ï¼š12 æ—¶é—´æ­¥\n",
    "- è¾“å‡ºé•¿åº¦ï¼š12 æ—¶é—´æ­¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ad7fa",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "from models.model import PatchSTG\n",
    "from lib.utils import log_string, _compute_loss, metric\n",
    "from lib.odps_data_loader import ODPSDataLoader\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸš€ PatchSTG æ¨¡å‹è®­ç»ƒ\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA è®¾å¤‡: {torch.cuda.get_device_name(0)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d629a",
   "metadata": {},
   "source": [
    "## 2. é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–é…ç½®æ–‡ä»¶\n",
    "config_file = 'config/ODPS.conf'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "# æ–­è¨€ï¼šé…ç½®æ–‡ä»¶å­˜åœ¨\n",
    "assert os.path.exists(config_file), f\"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}\"\n",
    "print(f\"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_file}\")\n",
    "\n",
    "# è®­ç»ƒå‚æ•°\n",
    "args = {\n",
    "    # è®­ç»ƒé…ç½®\n",
    "    'cuda': config['train']['cuda'],\n",
    "    'seed': int(config['train']['seed']),\n",
    "    'batch_size': int(config['train']['batch_size']),\n",
    "    'max_epoch': int(config['train']['max_epoch']),\n",
    "    'learning_rate': float(config['train']['learning_rate']),\n",
    "    'weight_decay': float(config['train']['weight_decay']),\n",
    "    \n",
    "    # ODPS æ•°æ®é…ç½®\n",
    "    'odps_project': config['data']['odps_project'],\n",
    "    'odps_endpoint': config['data']['odps_endpoint'],\n",
    "    'odps_table': config['data']['odps_table'],\n",
    "    'odps_meta_table': config['data']['odps_meta_table'],\n",
    "    'adcode': config['data']['adcode'],\n",
    "    'start_date': config['data']['start_date'],\n",
    "    'end_date': config['data']['end_date'],\n",
    "    'input_len': int(config['data']['input_len']),\n",
    "    'output_len': int(config['data']['output_len']),\n",
    "    'train_ratio': float(config['data']['train_ratio']),\n",
    "    'val_ratio': float(config['data']['val_ratio']),\n",
    "    'test_ratio': float(config['data']['test_ratio']),\n",
    "    \n",
    "    # æ¨¡å‹å‚æ•°\n",
    "    'layers': int(config['param']['layers']),\n",
    "    'tem_patchsize': int(config['param']['tps']),\n",
    "    'tem_patchnum': int(config['param']['tpn']),\n",
    "    'factors': int(config['param']['factors']),\n",
    "    'recur_times': int(config['param']['recur']),\n",
    "    'spa_patchsize': int(config['param']['sps']),\n",
    "    'spa_patchnum': int(config['param']['spn']),\n",
    "    'tod': int(config['param']['tod']),\n",
    "    'dow': int(config['param']['dow']),\n",
    "    'input_dims': int(config['param']['id']),\n",
    "    'node_dims': int(config['param']['nd']),\n",
    "    'tod_dims': int(config['param']['td']),\n",
    "    'dow_dims': int(config['param']['dd']),\n",
    "    \n",
    "    # æ–‡ä»¶è·¯å¾„\n",
    "    'model_file': config['file']['model'],\n",
    "    'log_file': config['file']['log'],\n",
    "}\n",
    "\n",
    "# æ–­è¨€ï¼šå…³é”®å‚æ•°åˆæ³•æ€§\n",
    "assert args['batch_size'] > 0, \"batch_size å¿…é¡» > 0\"\n",
    "assert args['max_epoch'] > 0, \"max_epoch å¿…é¡» > 0\"\n",
    "assert args['learning_rate'] > 0, \"learning_rate å¿…é¡» > 0\"\n",
    "assert 0 < args['train_ratio'] < 1, \"train_ratio å¿…é¡»åœ¨ (0, 1) ä¹‹é—´\"\n",
    "assert 0 < args['val_ratio'] < 1, \"val_ratio å¿…é¡»åœ¨ (0, 1) ä¹‹é—´\"\n",
    "assert 0 < args['test_ratio'] < 1, \"test_ratio å¿…é¡»åœ¨ (0, 1) ä¹‹é—´\"\n",
    "assert abs(args['train_ratio'] + args['val_ratio'] + args['test_ratio'] - 1.0) < 0.01, \\\n",
    "    \"train_ratio + val_ratio + test_ratio å¿…é¡»ç­‰äº 1.0\"\n",
    "\n",
    "print(\"\\nğŸ“‹ è®­ç»ƒé…ç½®:\")\n",
    "print(f\"  åŸå¸‚ä»£ç : {args['adcode']} (åŒ—äº¬)\")\n",
    "print(f\"  æ—¥æœŸèŒƒå›´: {args['start_date']} ~ {args['end_date']}\")\n",
    "print(f\"  Batch Size: {args['batch_size']}\")\n",
    "print(f\"  Max Epochs: {args['max_epoch']}\")\n",
    "print(f\"  Learning Rate: {args['learning_rate']}\")\n",
    "print(f\"  æ•°æ®åˆ’åˆ†: {args['train_ratio']:.0%} / {args['val_ratio']:.0%} / {args['test_ratio']:.0%}\")\n",
    "print()\n",
    "\n",
    "# åˆ›å»ºå¿…è¦ç›®å½•\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "os.makedirs('log', exist_ok=True)\n",
    "print(\"âœ… ç›®å½•å‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a9813b",
   "metadata": {},
   "source": [
    "## 3. è®¾ç½®éšæœºç§å­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4587fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§\n",
    "if args['seed'] is not None:\n",
    "    random.seed(args['seed'])\n",
    "    np.random.seed(args['seed'])\n",
    "    torch.manual_seed(args['seed'])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(args['seed'])\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    print(f\"âœ… éšæœºç§å­å·²è®¾ç½®: {args['seed']}\")\n",
    "else:\n",
    "    print(\"âš ï¸  æœªè®¾ç½®éšæœºç§å­ï¼Œç»“æœå¯èƒ½ä¸å¯é‡å¤\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8d8bf",
   "metadata": {},
   "source": [
    "## 4. åˆå§‹åŒ–æ—¥å¿—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcdacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰“å¼€æ—¥å¿—æ–‡ä»¶\n",
    "log = open(args['log_file'], 'w')\n",
    "\n",
    "# æ–­è¨€ï¼šæ—¥å¿—æ–‡ä»¶å¯å†™\n",
    "assert log.writable(), f\"æ—¥å¿—æ–‡ä»¶ä¸å¯å†™: {args['log_file']}\"\n",
    "\n",
    "# è®°å½•é…ç½®\n",
    "log_string(log, '=' * 80)\n",
    "log_string(log, 'PatchSTG æ¨¡å‹è®­ç»ƒ')\n",
    "log_string(log, '=' * 80)\n",
    "log_string(log, f\"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "log_string(log, f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "log_string(log, f\"CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "log_string(log, '')\n",
    "log_string(log, '------------ é…ç½®å‚æ•° -------------')\n",
    "for k, v in args.items():\n",
    "    log_string(log, f'{k}: {v}')\n",
    "log_string(log, '-------------- End ----------------')\n",
    "log_string(log, '')\n",
    "\n",
    "print(f\"âœ… æ—¥å¿—æ–‡ä»¶åˆå§‹åŒ–å®Œæˆ: {args['log_file']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056131d",
   "metadata": {},
   "source": [
    "## 5. åŠ è½½æ•°æ®\n",
    "\n",
    "âš ï¸ **è¿™ä¸€æ­¥å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´**ï¼Œå–å†³äºæ•°æ®é‡å’Œç½‘ç»œé€Ÿåº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_string(log, '\\n------------ åŠ è½½æ•°æ® -------------')\n",
    "print(\"ğŸ“Š å¼€å§‹åŠ è½½æ•°æ®...\")\n",
    "print(\"â³ è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\\n\")\n",
    "\n",
    "try:\n",
    "    # åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "    data_loader = ODPSDataLoader(args, log)\n",
    "    \n",
    "    # æ–­è¨€ï¼šæ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ\n",
    "    assert data_loader is not None, \"æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥\"\n",
    "    log_string(log, 'âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ')\n",
    "    \n",
    "    # åŠ è½½æ•°æ®\n",
    "    data_loader.load_data()\n",
    "    \n",
    "    # æ–­è¨€ï¼šæ•°æ®åŠ è½½æˆåŠŸ\n",
    "    assert data_loader._loaded, \"æ•°æ®åŠ è½½å¤±è´¥\"\n",
    "    log_string(log, 'âœ… æ•°æ®åŠ è½½å®Œæˆ')\n",
    "    \n",
    "    # è·å–æ•°æ®\n",
    "    trainX, trainY, trainXTE, trainYTE = data_loader.get_train_data()\n",
    "    valX, valY, valXTE, valYTE = data_loader.get_val_data()\n",
    "    testX, testY, testXTE, testYTE = data_loader.get_test_data()\n",
    "    mean, std = data_loader.get_normalization_params()\n",
    "    ori_parts_idx, reo_parts_idx, reo_all_idx = data_loader.get_patch_indices()\n",
    "    \n",
    "    # æ–­è¨€ï¼šæ•°æ®å½¢çŠ¶æ­£ç¡®\n",
    "    assert trainX.ndim == 4, f\"trainX ç»´åº¦é”™è¯¯: {trainX.ndim}, æœŸæœ› 4\"\n",
    "    assert trainY.ndim == 4, f\"trainY ç»´åº¦é”™è¯¯: {trainY.ndim}, æœŸæœ› 4\"\n",
    "    assert trainXTE.ndim == 3, f\"trainXTE ç»´åº¦é”™è¯¯: {trainXTE.ndim}, æœŸæœ› 3\"\n",
    "    \n",
    "    # æ–­è¨€ï¼šæ•°æ®å½¢çŠ¶ä¸€è‡´\n",
    "    assert trainX.shape[0] == trainY.shape[0] == trainXTE.shape[0], \"è®­ç»ƒé›†æ ·æœ¬æ•°ä¸ä¸€è‡´\"\n",
    "    assert valX.shape[0] == valY.shape[0] == valXTE.shape[0], \"éªŒè¯é›†æ ·æœ¬æ•°ä¸ä¸€è‡´\"\n",
    "    assert testX.shape[0] == testY.shape[0] == testXTE.shape[0], \"æµ‹è¯•é›†æ ·æœ¬æ•°ä¸ä¸€è‡´\"\n",
    "    \n",
    "    # æ–­è¨€ï¼šæ²¡æœ‰ NaN æˆ– Inf\n",
    "    assert not np.any(np.isnan(trainX)), \"trainX åŒ…å« NaN å€¼\"\n",
    "    assert not np.any(np.isinf(trainX)), \"trainX åŒ…å« Inf å€¼\"\n",
    "    assert not np.any(np.isnan(trainY)), \"trainY åŒ…å« NaN å€¼\"\n",
    "    assert not np.any(np.isinf(trainY)), \"trainY åŒ…å« Inf å€¼\"\n",
    "    \n",
    "    # æ–­è¨€ï¼šå½’ä¸€åŒ–å‚æ•°æœ‰æ•ˆ\n",
    "    assert std > 1e-6, f\"æ ‡å‡†å·®è¿‡å°: {std}\"\n",
    "    assert not np.isnan(mean), \"å‡å€¼ä¸º NaN\"\n",
    "    assert not np.isnan(std), \"æ ‡å‡†å·®ä¸º NaN\"\n",
    "    \n",
    "    # æ–­è¨€ï¼šPatch ç´¢å¼•æœ‰æ•ˆ\n",
    "    assert ori_parts_idx is not None, \"ori_parts_idx ä¸º None\"\n",
    "    assert reo_parts_idx is not None, \"reo_parts_idx ä¸º None\"\n",
    "    assert reo_all_idx is not None, \"reo_all_idx ä¸º None\"\n",
    "    \n",
    "    node_num = data_loader.node_num\n",
    "    \n",
    "    # æ–­è¨€ï¼šèŠ‚ç‚¹æ•°é‡åˆç†\n",
    "    assert node_num > 0, \"èŠ‚ç‚¹æ•°é‡å¿…é¡» > 0\"\n",
    "    assert node_num == trainX.shape[2], f\"èŠ‚ç‚¹æ•°é‡ä¸åŒ¹é…: {node_num} vs {trainX.shape[2]}\"\n",
    "    \n",
    "    log_string(log, f'\\næ•°æ®é›†ç»Ÿè®¡:')\n",
    "    log_string(log, f'  è®­ç»ƒé›†: {trainX.shape[0]} æ ·æœ¬')\n",
    "    log_string(log, f'  éªŒè¯é›†: {valX.shape[0]} æ ·æœ¬')\n",
    "    log_string(log, f'  æµ‹è¯•é›†: {testX.shape[0]} æ ·æœ¬')\n",
    "    log_string(log, f'  èŠ‚ç‚¹æ•°: {node_num}')\n",
    "    log_string(log, f'  å½’ä¸€åŒ–å‚æ•°: mean={mean:.4f}, std={std:.4f}')\n",
    "    log_string(log, f'  æ•°æ®å½¢çŠ¶: {trainX.shape}')\n",
    "    log_string(log, '------------ End -------------\\n')\n",
    "    \n",
    "    print(\"\\nâœ… æ•°æ®åŠ è½½æˆåŠŸï¼\")\n",
    "    print(f\"  è®­ç»ƒé›†: {trainX.shape[0]} æ ·æœ¬\")\n",
    "    print(f\"  éªŒè¯é›†: {valX.shape[0]} æ ·æœ¬\")\n",
    "    print(f\"  æµ‹è¯•é›†: {testX.shape[0]} æ ·æœ¬\")\n",
    "    print(f\"  èŠ‚ç‚¹æ•°: {node_num}\")\n",
    "    print(f\"  å½’ä¸€åŒ–: mean={mean:.4f}, std={std:.4f}\")\n",
    "    print()\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = f\"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}\"\n",
    "    log_string(log, f'\\nâŒ {error_msg}')\n",
    "    print(f\"\\nâŒ {error_msg}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    log.close()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0160b8",
   "metadata": {},
   "source": [
    "## 6. æ•°æ®è´¨é‡æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥...\\n\")\n",
    "\n",
    "# æ£€æŸ¥å¯†é›†æ€§\n",
    "def check_density(X, name):\n",
    "    nodes_with_data = []\n",
    "    for i in range(min(10, len(X))):\n",
    "        has_data = (X[i, :, :, 0] > 0).any(axis=0)\n",
    "        num_nodes = has_data.sum()\n",
    "        nodes_with_data.append(num_nodes)\n",
    "    \n",
    "    avg_nodes = np.mean(nodes_with_data)\n",
    "    density = avg_nodes / node_num * 100\n",
    "    \n",
    "    log_string(log, f'{name} å¯†é›†æ€§: {avg_nodes:.1f}/{node_num} ({density:.1f}%)')\n",
    "    print(f\"{name} å¯†é›†æ€§: {avg_nodes:.1f}/{node_num} ({density:.1f}%)\")\n",
    "    \n",
    "    # æ–­è¨€ï¼šæ•°æ®å¯†é›†æ€§\n",
    "    assert density > 10, f\"{name} æ•°æ®è¿‡äºç¨€ç– ({density:.1f}% < 10%)\"\n",
    "    \n",
    "    return density\n",
    "\n",
    "train_density = check_density(trainX, \"è®­ç»ƒé›†\")\n",
    "val_density = check_density(valX, \"éªŒè¯é›†\")\n",
    "\n",
    "# æ£€æŸ¥å€¼èŒƒå›´\n",
    "log_string(log, f'\\næ•°æ®å€¼èŒƒå›´:')\n",
    "log_string(log, f'  è®­ç»ƒé›†: [{trainX.min():.2f}, {trainX.max():.2f}]')\n",
    "log_string(log, f'  éªŒè¯é›†: [{valX.min():.2f}, {valX.max():.2f}]')\n",
    "log_string(log, f'  æµ‹è¯•é›†: [{testX.min():.2f}, {testX.max():.2f}]')\n",
    "\n",
    "print(f\"\\næ•°æ®å€¼èŒƒå›´:\")\n",
    "print(f\"  è®­ç»ƒé›†: [{trainX.min():.2f}, {trainX.max():.2f}]\")\n",
    "print(f\"  éªŒè¯é›†: [{valX.min():.2f}, {valX.max():.2f}]\")\n",
    "print(f\"  æµ‹è¯•é›†: [{testX.min():.2f}, {testX.max():.2f}]\")\n",
    "\n",
    "if train_density > 50:\n",
    "    print(f\"\\nâœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡ - å¯†é›†æ ¼å¼ ({train_density:.1f}%)\")\n",
    "    log_string(log, f'\\nâœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡ - å¯†é›†æ ¼å¼ ({train_density:.1f}%)')\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  æ•°æ®å¯†é›†æ€§è¾ƒä½ ({train_density:.1f}%)ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ\")\n",
    "    log_string(log, f'\\nâš ï¸  æ•°æ®å¯†é›†æ€§è¾ƒä½ ({train_density:.1f}%)ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2508bc4",
   "metadata": {},
   "source": [
    "## 7. æ„å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_string(log, '\\n------------ æ„å»ºæ¨¡å‹ -------------')\n",
    "print(\"ğŸ—ï¸  æ„å»º PatchSTG æ¨¡å‹...\\n\")\n",
    "\n",
    "try:\n",
    "    # é€‰æ‹©è®¾å¤‡\n",
    "    device = torch.device(f\"cuda:{args['cuda']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    log_string(log, f'è®¾å¤‡: {device}')\n",
    "    print(f\"è®¾å¤‡: {device}\")\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    model = PatchSTG(\n",
    "        args['output_len'], \n",
    "        args['tem_patchsize'], \n",
    "        args['tem_patchnum'],\n",
    "        node_num,  # ä½¿ç”¨å®é™…çš„èŠ‚ç‚¹æ•°\n",
    "        args['spa_patchsize'], \n",
    "        args['spa_patchnum'],\n",
    "        args['tod'], \n",
    "        args['dow'],\n",
    "        args['layers'], \n",
    "        args['factors'],\n",
    "        args['input_dims'], \n",
    "        args['node_dims'], \n",
    "        args['tod_dims'], \n",
    "        args['dow_dims'],\n",
    "        ori_parts_idx, \n",
    "        reo_parts_idx, \n",
    "        reo_all_idx\n",
    "    ).to(device)\n",
    "    \n",
    "    # æ–­è¨€ï¼šæ¨¡å‹åˆ›å»ºæˆåŠŸ\n",
    "    assert model is not None, \"æ¨¡å‹åˆ›å»ºå¤±è´¥\"\n",
    "    \n",
    "    # è®¡ç®—æ¨¡å‹å‚æ•°é‡\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    log_string(log, f'æ¨¡å‹å‚æ•°: {total_params:,}')\n",
    "    log_string(log, f'å¯è®­ç»ƒå‚æ•°: {trainable_params:,}')\n",
    "    print(f\"æ¨¡å‹å‚æ•°: {total_params:,}\")\n",
    "    print(f\"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\")\n",
    "    \n",
    "    # åˆ›å»ºä¼˜åŒ–å™¨\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=args['learning_rate'],\n",
    "        weight_decay=args['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # æ–­è¨€ï¼šä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ\n",
    "    assert optimizer is not None, \"ä¼˜åŒ–å™¨åˆ›å»ºå¤±è´¥\"\n",
    "    \n",
    "    # å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=[1, 35, 40],\n",
    "        gamma=0.5,\n",
    "    )\n",
    "    \n",
    "    log_string(log, f'ä¼˜åŒ–å™¨: AdamW (lr={args[\"learning_rate\"]}, wd={args[\"weight_decay\"]})')\n",
    "    log_string(log, f'å­¦ä¹ ç‡è°ƒåº¦: MultiStepLR (milestones=[1, 35, 40], gamma=0.5)')\n",
    "    log_string(log, '------------ End -------------\\n')\n",
    "    \n",
    "    print(f\"\\nâœ… æ¨¡å‹æ„å»ºæˆåŠŸ\")\n",
    "    print(f\"  ä¼˜åŒ–å™¨: AdamW\")\n",
    "    print(f\"  å­¦ä¹ ç‡: {args['learning_rate']}\")\n",
    "    print()\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = f\"æ¨¡å‹æ„å»ºå¤±è´¥: {str(e)}\"\n",
    "    log_string(log, f'\\nâŒ {error_msg}')\n",
    "    print(f\"\\nâŒ {error_msg}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    log.close()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4ce89",
   "metadata": {},
   "source": [
    "## 8. å®šä¹‰éªŒè¯å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valX, valY, valXTE, mean, std, device, batch_size, log):\n",
    "    \"\"\"\n",
    "    éªŒè¯å‡½æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "        maes, rmses, mapes: æ¯ä¸ªæ—¶é—´æ­¥å’Œå¹³å‡çš„æŒ‡æ ‡\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_val = valX.shape[0]\n",
    "    pred = []\n",
    "    label = []\n",
    "\n",
    "    num_batch = math.ceil(num_val / batch_size)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(num_batch):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min(num_val, (batch_idx + 1) * batch_size)\n",
    "\n",
    "            X = valX[start_idx:end_idx]\n",
    "            Y = valY[start_idx:end_idx]\n",
    "            TE = torch.from_numpy(valXTE[start_idx:end_idx]).to(device)\n",
    "            NormX = torch.from_numpy((X - mean) / std).float().to(device)\n",
    "\n",
    "            # æ–­è¨€ï¼šè¾“å…¥å½¢çŠ¶æ­£ç¡®\n",
    "            assert NormX.shape[1] == 12, f\"è¾“å…¥åºåˆ—é•¿åº¦é”™è¯¯: {NormX.shape[1]}\"\n",
    "            assert TE.shape[1] == 12, f\"æ—¶é—´ç‰¹å¾é•¿åº¦é”™è¯¯: {TE.shape[1]}\"\n",
    "            \n",
    "            y_hat = model(NormX, TE)\n",
    "            \n",
    "            # æ–­è¨€ï¼šè¾“å‡ºå½¢çŠ¶æ­£ç¡®\n",
    "            assert y_hat.shape[1] == 12, f\"è¾“å‡ºåºåˆ—é•¿åº¦é”™è¯¯: {y_hat.shape[1]}\"\n",
    "\n",
    "            pred.append(y_hat.cpu().numpy() * std + mean)\n",
    "            label.append(Y)\n",
    "    \n",
    "    pred = np.concatenate(pred, axis=0)\n",
    "    label = np.concatenate(label, axis=0)\n",
    "    \n",
    "    # æ–­è¨€ï¼šé¢„æµ‹å’Œæ ‡ç­¾å½¢çŠ¶ä¸€è‡´\n",
    "    assert pred.shape == label.shape, f\"é¢„æµ‹å’Œæ ‡ç­¾å½¢çŠ¶ä¸ä¸€è‡´: {pred.shape} vs {label.shape}\"\n",
    "\n",
    "    maes = []\n",
    "    rmses = []\n",
    "    mapes = []\n",
    "\n",
    "    for i in range(pred.shape[1]):\n",
    "        mae, rmse, mape = metric(pred[:, i, :], label[:, i, :])\n",
    "        maes.append(mae)\n",
    "        rmses.append(rmse)\n",
    "        mapes.append(mape)\n",
    "        log_string(log, f'  æ—¶é—´æ­¥ {i+1}: MAE={mae:.4f}, RMSE={rmse:.4f}, MAPE={mape:.4f}')\n",
    "    \n",
    "    mae, rmse, mape = metric(pred, label)\n",
    "    maes.append(mae)\n",
    "    rmses.append(rmse)\n",
    "    mapes.append(mape)\n",
    "    log_string(log, f'  å¹³å‡: MAE={mae:.4f}, RMSE={rmse:.4f}, MAPE={mape:.4f}')\n",
    "    \n",
    "    return np.stack(maes, 0), np.stack(rmses, 0), np.stack(mapes, 0)\n",
    "\n",
    "print(\"âœ… éªŒè¯å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f1099",
   "metadata": {},
   "source": [
    "## 9. å¼€å§‹è®­ç»ƒ\n",
    "\n",
    "âš ï¸ **è¿™ä¸€æ­¥ä¼šè¿è¡Œå¾ˆé•¿æ—¶é—´**ï¼Œå–å†³äº epoch æ•°é‡å’Œæ•°æ®é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_string(log, '\\n' + '=' * 80)\n",
    "log_string(log, 'å¼€å§‹è®­ç»ƒ')\n",
    "log_string(log, '=' * 80)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸš€ å¼€å§‹è®­ç»ƒ\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"æ€» Epoch æ•°: {args['max_epoch']}\")\n",
    "print(f\"Batch Size: {args['batch_size']}\")\n",
    "print(f\"è®­ç»ƒæ ·æœ¬æ•°: {trainX.shape[0]}\")\n",
    "print(f\"æ¯ä¸ª Epoch çš„ Batch æ•°: {math.ceil(trainX.shape[0] / args['batch_size'])}\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "min_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "num_train = trainX.shape[0]\n",
    "\n",
    "# è®­ç»ƒå†å²è®°å½•\n",
    "train_losses = []\n",
    "val_maes = []\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, args['max_epoch'] + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # è®­ç»ƒæ¨¡å¼\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        batch_count = 0\n",
    "        \n",
    "        # æ‰“ä¹±è®­ç»ƒæ•°æ®\n",
    "        data_loader.shuffle_train_data()\n",
    "        trainX, trainY, trainXTE, trainYTE = data_loader.get_train_data()\n",
    "        \n",
    "        # æ–­è¨€ï¼šæ‰“ä¹±åæ•°æ®å½¢çŠ¶ä¸å˜\n",
    "        assert trainX.shape[0] == num_train, \"æ‰“ä¹±åæ ·æœ¬æ•°é‡æ”¹å˜\"\n",
    "        \n",
    "        num_batch = math.ceil(num_train / args['batch_size'])\n",
    "        \n",
    "        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦\n",
    "        pbar = tqdm(range(num_batch), desc=f\"Epoch {epoch}/{args['max_epoch']}\")\n",
    "        \n",
    "        for batch_idx in pbar:\n",
    "            start_idx = batch_idx * args['batch_size']\n",
    "            end_idx = min(num_train, (batch_idx + 1) * args['batch_size'])\n",
    "\n",
    "            X = trainX[start_idx:end_idx]\n",
    "            Y = trainY[start_idx:end_idx]\n",
    "            TE = torch.from_numpy(trainXTE[start_idx:end_idx]).to(device)\n",
    "            NormX = torch.from_numpy((X - mean) / std).float().to(device)\n",
    "            Y_tensor = torch.from_numpy(Y).float().to(device)\n",
    "            \n",
    "            # æ–­è¨€ï¼šæ‰¹æ¬¡æ•°æ®å½¢çŠ¶æ­£ç¡®\n",
    "            assert NormX.shape[0] > 0, \"æ‰¹æ¬¡å¤§å°ä¸º 0\"\n",
    "            assert not torch.isnan(NormX).any(), \"è¾“å…¥åŒ…å« NaN\"\n",
    "            assert not torch.isinf(NormX).any(), \"è¾“å…¥åŒ…å« Inf\"\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(NormX, TE)\n",
    "            \n",
    "            # æ–­è¨€ï¼šè¾“å‡ºæœ‰æ•ˆ\n",
    "            assert not torch.isnan(y_hat).any(), \"æ¨¡å‹è¾“å‡ºåŒ…å« NaN\"\n",
    "            assert not torch.isinf(y_hat).any(), \"æ¨¡å‹è¾“å‡ºåŒ…å« Inf\"\n",
    "            \n",
    "            loss = _compute_loss(Y_tensor, y_hat * std + mean)\n",
    "            \n",
    "            # æ–­è¨€ï¼šæŸå¤±æœ‰æ•ˆ\n",
    "            assert not torch.isnan(loss), \"æŸå¤±ä¸º NaN\"\n",
    "            assert not torch.isinf(loss), \"æŸå¤±ä¸º Inf\"\n",
    "            assert loss.item() >= 0, \"æŸå¤±ä¸ºè´Ÿæ•°\"\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_sum += loss.cpu().item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # æ›´æ–°è¿›åº¦æ¡\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # Epoch ç»“æŸ\n",
    "        avg_train_loss = train_loss_sum / batch_count\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # éªŒè¯\n",
    "        log_string(log, f'\\nEpoch {epoch}/{args[\"max_epoch\"]}:')\n",
    "        log_string(log, f'  è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}')\n",
    "        log_string(log, f'  å­¦ä¹ ç‡: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        log_string(log, f'  ç”¨æ—¶: {time.time() - epoch_start_time:.1f}s')\n",
    "        log_string(log, '\\néªŒè¯ç»“æœ:')\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch} å®Œæˆ:\")\n",
    "        print(f\"  è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}\")\n",
    "        print(f\"  å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(f\"  ç”¨æ—¶: {time.time() - epoch_start_time:.1f}s\")\n",
    "        print(\"\\néªŒè¯ä¸­...\")\n",
    "        \n",
    "        maes, rmses, mapes = validate(\n",
    "            model, valX, valY, valXTE, mean, std, device, args['batch_size'], log\n",
    "        )\n",
    "        \n",
    "        val_mae = maes[-1]  # å¹³å‡ MAE\n",
    "        val_maes.append(val_mae)\n",
    "        \n",
    "        print(f\"  éªŒè¯ MAE: {val_mae:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # æ›´æ–°å­¦ä¹ ç‡\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        if val_mae < min_val_loss:\n",
    "            min_val_loss = val_mae\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), args['model_file'])\n",
    "            log_string(log, f'\\nâœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Epoch {epoch}, MAE={val_mae:.4f})')\n",
    "            print(f\"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Epoch {epoch}, MAE={val_mae:.4f})\")\n",
    "        \n",
    "        log_string(log, '\\n' + '-' * 80 + '\\n')\n",
    "    \n",
    "    log_string(log, '\\n' + '=' * 80)\n",
    "    log_string(log, 'è®­ç»ƒå®Œæˆ')\n",
    "    log_string(log, '=' * 80)\n",
    "    log_string(log, f'æœ€ä½³ Epoch: {best_epoch}')\n",
    "    log_string(log, f'æœ€ä½³éªŒè¯ MAE: {min_val_loss:.4f}')\n",
    "    log_string(log, f'æ¨¡å‹ä¿å­˜ä½ç½®: {args[\"model_file\"]}')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ‰ è®­ç»ƒå®Œæˆï¼\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"æœ€ä½³ Epoch: {best_epoch}\")\n",
    "    print(f\"æœ€ä½³éªŒè¯ MAE: {min_val_loss:.4f}\")\n",
    "    print(f\"æ¨¡å‹ä¿å­˜ä½ç½®: {args['model_file']}\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    log_string(log, '\\n\\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­')\n",
    "    print(\"\\n\\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­\")\n",
    "    print(f\"å·²å®Œæˆ {epoch-1} ä¸ª epoch\")\n",
    "    if best_epoch > 0:\n",
    "        print(f\"æœ€ä½³æ¨¡å‹å·²ä¿å­˜åœ¨ Epoch {best_epoch}\")\n",
    "\n",
    "except Exception as e:\n",
    "    error_msg = f\"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}\"\n",
    "    log_string(log, f'\\nâŒ {error_msg}')\n",
    "    print(f\"\\nâŒ {error_msg}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba31c0",
   "metadata": {},
   "source": [
    "## 10. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # è®­ç»ƒæŸå¤±æ›²çº¿\n",
    "    ax1.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Train Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # éªŒè¯ MAE æ›²çº¿\n",
    "    ax2.plot(range(1, len(val_maes) + 1), val_maes, 'r-', label='Validation MAE')\n",
    "    ax2.axvline(x=best_epoch, color='g', linestyle='--', label=f'Best Epoch ({best_epoch})')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_title('Validation MAE')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: training_curves.png\")\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸  matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  å¯è§†åŒ–å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41360257",
   "metadata": {},
   "source": [
    "## 11. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd20e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_string(log, '\\n' + '=' * 80)\n",
    "log_string(log, 'æµ‹è¯•é›†è¯„ä¼°')\n",
    "log_string(log, '=' * 80)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Š æµ‹è¯•é›†è¯„ä¼°\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "    model.load_state_dict(torch.load(args['model_file'], map_location=device))\n",
    "    log_string(log, f'âœ… åŠ è½½æœ€ä½³æ¨¡å‹: {args[\"model_file\"]}')\n",
    "    print(f\"âœ… åŠ è½½æœ€ä½³æ¨¡å‹: {args['model_file']}\")\n",
    "    print()\n",
    "    \n",
    "    model.eval()\n",
    "    num_test = testX.shape[0]\n",
    "    pred = []\n",
    "    label = []\n",
    "\n",
    "    num_batch = math.ceil(num_test / args['batch_size'])\n",
    "    \n",
    "    print(\"é¢„æµ‹ä¸­...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in tqdm(range(num_batch), desc=\"æµ‹è¯•\"):\n",
    "            start_idx = batch_idx * args['batch_size']\n",
    "            end_idx = min(num_test, (batch_idx + 1) * args['batch_size'])\n",
    "\n",
    "            X = testX[start_idx:end_idx]\n",
    "            Y = testY[start_idx:end_idx]\n",
    "            TE = torch.from_numpy(testXTE[start_idx:end_idx]).to(device)\n",
    "            NormX = torch.from_numpy((X - mean) / std).float().to(device)\n",
    "\n",
    "            y_hat = model(NormX, TE)\n",
    "\n",
    "            pred.append(y_hat.cpu().numpy() * std + mean)\n",
    "            label.append(Y)\n",
    "    \n",
    "    pred = np.concatenate(pred, axis=0)\n",
    "    label = np.concatenate(label, axis=0)\n",
    "    \n",
    "    # æ–­è¨€ï¼šé¢„æµ‹å’Œæ ‡ç­¾å½¢çŠ¶ä¸€è‡´\n",
    "    assert pred.shape == label.shape, f\"é¢„æµ‹å’Œæ ‡ç­¾å½¢çŠ¶ä¸ä¸€è‡´: {pred.shape} vs {label.shape}\"\n",
    "\n",
    "    print(\"\\nè®¡ç®—æŒ‡æ ‡...\\n\")\n",
    "    \n",
    "    maes = []\n",
    "    rmses = []\n",
    "    mapes = []\n",
    "\n",
    "    log_string(log, '\\nå„æ—¶é—´æ­¥æŒ‡æ ‡:')\n",
    "    print(\"å„æ—¶é—´æ­¥æŒ‡æ ‡:\")\n",
    "    \n",
    "    for i in range(pred.shape[1]):\n",
    "        mae, rmse, mape = metric(pred[:, i, :], label[:, i, :])\n",
    "        maes.append(mae)\n",
    "        rmses.append(rmse)\n",
    "        mapes.append(mape)\n",
    "        log_string(log, f'  æ—¶é—´æ­¥ {i+1:2d}: MAE={mae:6.4f}, RMSE={rmse:6.4f}, MAPE={mape:6.4f}')\n",
    "        print(f\"  æ—¶é—´æ­¥ {i+1:2d}: MAE={mae:6.4f}, RMSE={rmse:6.4f}, MAPE={mape:6.4f}\")\n",
    "    \n",
    "    mae, rmse, mape = metric(pred, label)\n",
    "    maes.append(mae)\n",
    "    rmses.append(rmse)\n",
    "    mapes.append(mape)\n",
    "    \n",
    "    log_string(log, '\\nå¹³å‡æŒ‡æ ‡:')\n",
    "    log_string(log, f'  MAE:  {mae:.4f}')\n",
    "    log_string(log, f'  RMSE: {rmse:.4f}')\n",
    "    log_string(log, f'  MAPE: {mape:.4f}')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“ˆ æœ€ç»ˆæµ‹è¯•ç»“æœ\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAPE: {mape:.4f}\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = f\"æµ‹è¯•è¯„ä¼°å¤±è´¥: {str(e)}\"\n",
    "    log_string(log, f'\\nâŒ {error_msg}')\n",
    "    print(f\"\\nâŒ {error_msg}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc791d",
   "metadata": {},
   "source": [
    "## 12. å…³é—­æ—¥å¿—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f96b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_string(log, f'\\nç»“æŸæ—¶é—´: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "log_string(log, '\\n' + '=' * 80)\n",
    "log.close()\n",
    "\n",
    "print(f\"\\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nâœ… æ—¥å¿—å·²ä¿å­˜: {args['log_file']}\")\n",
    "print(f\"âœ… æ¨¡å‹å·²ä¿å­˜: {args['model_file']}\")\n",
    "print(\"\\nğŸ‰ å…¨éƒ¨å®Œæˆï¼\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
