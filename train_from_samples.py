"""
ä»é¢„å¤„ç†æ ·æœ¬è¡¨ç›´æ¥è®­ç»ƒ - æ–¹æ¡ˆ 2ï¼ˆæé€Ÿç‰ˆï¼‰

åŠŸèƒ½ï¼š
1. ä» ODPS æ ·æœ¬è¡¨ç›´æ¥è¯»å–å·²å¤„ç†çš„æ ·æœ¬
2. ååºåˆ—åŒ–ä¸º numpy æ•°ç»„
3. å¼€å§‹è®­ç»ƒï¼ˆæ— éœ€ä»»ä½•æ•°æ®å¤„ç†ï¼‰

é€Ÿåº¦ï¼šç§’çº§åŠ è½½ â†’ ç«‹å³å¼€å§‹è®­ç»ƒï¼
"""

import os
import sys
import math
import time
import random
import argparse
import json
import numpy as np
import torch
import torch.nn as nn
from tqdm import tqdm
from odps import ODPS
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from models.model import PatchSTG
from lib.utils import log_string, _compute_loss, metric


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='ä»æ ·æœ¬è¡¨è®­ç»ƒ PatchSTG')
    
    # ODPS é…ç½®
    parser.add_argument('--odps_project', type=str, required=True)
    parser.add_argument('--odps_endpoint', type=str, required=True)
    parser.add_argument('--sample_table', type=str, required=True,
                        help='é¢„å¤„ç†å¥½çš„æ ·æœ¬è¡¨å')
    parser.add_argument('--metadata_file', type=str, required=True,
                        help='é¢„å¤„ç†å…ƒæ•°æ®æ–‡ä»¶ (JSON)')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--max_epoch', type=int, default=50)
    parser.add_argument('--learning_rate', type=float, default=0.001)
    parser.add_argument('--weight_decay', type=float, default=0.0001)
    parser.add_argument('--seed', type=int, default=10)
    parser.add_argument('--cuda', type=str, default='0')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--layers', type=int, default=3)
    parser.add_argument('--tem_patchsize', type=int, default=12)
    parser.add_argument('--tem_patchnum', type=int, default=1)
    parser.add_argument('--factors', type=int, default=5)
    parser.add_argument('--spa_patchsize', type=int, default=4)
    parser.add_argument('--spa_patchnum', type=int, default=6)
    parser.add_argument('--tod', type=int, default=288)
    parser.add_argument('--dow', type=int, default=7)
    parser.add_argument('--input_dims', type=int, default=1)
    parser.add_argument('--node_dims', type=int, default=64)
    parser.add_argument('--tod_dims', type=int, default=64)
    parser.add_argument('--dow_dims', type=int, default=64)
    
    # è¾“å‡º
    parser.add_argument('--model_file', type=str, default=None)
    parser.add_argument('--log_file', type=str, default=None)
    
    return parser.parse_args()


def deserialize_array(s, shape):
    """ååºåˆ—åŒ–å­—ç¬¦ä¸²ä¸º numpy æ•°ç»„"""
    arr = np.array([float(x) for x in s.split(',')])
    return arr.reshape(shape)


def load_samples_from_odps(odps_client, table_name, split, metadata):
    """
    ä» ODPS æ ·æœ¬è¡¨åŠ è½½æ•°æ®
    
    å‚æ•°:
        odps_client: ODPS å®¢æˆ·ç«¯
        table_name: è¡¨å
        split: 'train' / 'val' / 'test'
        metadata: å…ƒæ•°æ®å­—å…¸
    
    è¿”å›:
        X, Y, TE_X, TE_Y (numpy æ•°ç»„)
    """
    print(f"\nğŸ“¥ åŠ è½½ {split} æ•°æ®ä» {table_name}...")
    
    # æŸ¥è¯¢æŒ‡å®š split çš„æ•°æ®
    query = f"""
    SELECT X, Y, TE_X, TE_Y
    FROM {table_name}
    WHERE split = '{split}'
    """
    
    # ä»å…ƒæ•°æ®è·å–å½¢çŠ¶ä¿¡æ¯
    num_nodes = metadata['node_num']
    input_len = metadata['input_len']
    output_len = metadata['output_len']
    
    X_list = []
    Y_list = []
    TE_X_list = []
    TE_Y_list = []
    
    with odps_client.execute_sql(query).open_reader() as reader:
        for record in tqdm(reader, desc=f"è¯»å– {split}"):
            # ååºåˆ—åŒ–
            X = deserialize_array(record[0], (input_len, num_nodes, 1))
            Y = deserialize_array(record[1], (output_len, num_nodes, 1))
            TE_X = deserialize_array(record[2], (input_len, 2))
            TE_Y = deserialize_array(record[3], (output_len, 2))
            
            X_list.append(X)
            Y_list.append(Y)
            TE_X_list.append(TE_X)
            TE_Y_list.append(TE_Y)
    
    # è½¬æ¢ä¸º numpy æ•°ç»„
    X = np.array(X_list)
    Y = np.array(Y_list)
    TE_X = np.array(TE_X_list)
    TE_Y = np.array(TE_Y_list)
    
    print(f"âœ… {split} æ•°æ®åŠ è½½å®Œæˆ")
    print(f"   X: {X.shape}")
    print(f"   Y: {Y.shape}")
    print(f"   TE_X: {TE_X.shape}")
    print(f"   TE_Y: {TE_Y.shape}")
    
    return X, Y, TE_X, TE_Y


def validate(model, valX, valY, valXTE, mean, std, device, batch_size):
    """éªŒè¯å‡½æ•°"""
    model.eval()
    num_val = valX.shape[0]
    pred = []
    label = []

    num_batch = math.ceil(num_val / batch_size)
    
    with torch.no_grad():
        for batch_idx in range(num_batch):
            start_idx = batch_idx * batch_size
            end_idx = min(num_val, (batch_idx + 1) * batch_size)

            X = valX[start_idx:end_idx]
            Y = valY[start_idx:end_idx]
            TE = torch.from_numpy(valXTE[start_idx:end_idx]).to(device)
            NormX = torch.from_numpy((X - mean) / std).float().to(device)

            y_hat = model(NormX, TE)
            pred.append(y_hat.cpu().numpy() * std + mean)
            label.append(Y)
    
    pred = np.concatenate(pred, axis=0)
    label = np.concatenate(label, axis=0)

    maes = []
    rmses = []
    mapes = []

    for i in range(pred.shape[1]):
        mae, rmse, mape = metric(pred[:, i, :], label[:, i, :])
        maes.append(mae)
        rmses.append(rmse)
        mapes.append(mape)
    
    mae, rmse, mape = metric(pred, label)
    maes.append(mae)
    rmses.append(rmse)
    mapes.append(mape)
    
    return np.stack(maes, 0), np.stack(rmses, 0), np.stack(mapes, 0)


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    print("=" * 80)
    print("ğŸš€ PatchSTG ä»æ ·æœ¬è¡¨è®­ç»ƒ - æ–¹æ¡ˆ 2ï¼ˆæé€Ÿç‰ˆï¼‰")
    print("=" * 80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # è¯»å–å…ƒæ•°æ®
    print("ğŸ“‹ è¯»å–å…ƒæ•°æ®...")
    with open(args.metadata_file, 'r') as f:
        metadata = json.load(f)
    
    print("å…ƒæ•°æ®:")
    for k, v in metadata.items():
        print(f"  {k}: {v}")
    print()
    
    # è®¾ç½®éšæœºç§å­
    if args.seed is not None:
        random.seed(args.seed)
        np.random.seed(args.seed)
        torch.manual_seed(args.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(args.seed)
        print(f"âœ… éšæœºç§å­: {args.seed}\n")
    
    # åˆå§‹åŒ–æ—¥å¿—
    if args.log_file is None:
        args.log_file = f"log/train_from_samples_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    if args.model_file is None:
        args.model_file = f"saved_models/model_from_samples_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
    
    os.makedirs('log', exist_ok=True)
    os.makedirs('saved_models', exist_ok=True)
    
    log = open(args.log_file, 'w')
    log_string(log, f"è®­ç»ƒå¼€å§‹: {datetime.now()}")
    
    # åˆå§‹åŒ– ODPS å®¢æˆ·ç«¯
    print("ğŸ”— è¿æ¥ ODPS...")
    access_id = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_ID')
    access_key = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_SECRET')
    
    if not access_id or not access_key:
        raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: ALIBABA_CLOUD_ACCESS_KEY_ID å’Œ ALIBABA_CLOUD_ACCESS_KEY_SECRET")
    
    odps_client = ODPS(access_id, access_key, args.odps_project, endpoint=args.odps_endpoint)
    print("âœ… ODPS è¿æ¥æˆåŠŸ\n")
    
    # åŠ è½½æ•°æ®ï¼ˆæå¿«ï¼ç›´æ¥è¯»å–å·²å¤„ç†æ ·æœ¬ï¼‰
    print("=" * 80)
    print("åŠ è½½æ•°æ®")
    print("=" * 80)
    
    trainX, trainY, trainXTE, trainYTE = load_samples_from_odps(
        odps_client, args.sample_table, 'train', metadata
    )
    valX, valY, valXTE, valYTE = load_samples_from_odps(
        odps_client, args.sample_table, 'val', metadata
    )
    testX, testY, testXTE, testYTE = load_samples_from_odps(
        odps_client, args.sample_table, 'test', metadata
    )
    
    mean = metadata['mean']
    std = metadata['std']
    node_num = metadata['node_num']
    
    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆï¼")
    print(f"  è®­ç»ƒé›†: {trainX.shape[0]} æ ·æœ¬")
    print(f"  éªŒè¯é›†: {valX.shape[0]} æ ·æœ¬")
    print(f"  æµ‹è¯•é›†: {testX.shape[0]} æ ·æœ¬")
    print(f"  èŠ‚ç‚¹æ•°: {node_num}")
    print()
    
    # æ„å»ºæ¨¡å‹
    print("=" * 80)
    print("æ„å»ºæ¨¡å‹")
    print("=" * 80)
    
    device = torch.device(f"cuda:{args.cuda}" if torch.cuda.is_available() else "cpu")
    print(f"è®¾å¤‡: {device}")
    
    # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–äº† patch ç´¢å¼•ï¼Œå®é™…åº”ä»å…ƒæ•°æ®åŠ è½½
    # ä¸ºç®€åŒ–ï¼Œè¿™é‡Œå‡è®¾ä½¿ç”¨é¡ºåºç´¢å¼•
    ori_parts_idx = list(range(node_num))
    reo_parts_idx = list(range(node_num))
    reo_all_idx = list(range(node_num))
    
    model = PatchSTG(
        args.output_len if hasattr(args, 'output_len') else metadata['output_len'],
        args.tem_patchsize,
        args.tem_patchnum,
        node_num,
        args.spa_patchsize,
        args.spa_patchnum,
        args.tod,
        args.dow,
        args.layers,
        args.factors,
        args.input_dims,
        args.node_dims,
        args.tod_dims,
        args.dow_dims,
        ori_parts_idx,
        reo_parts_idx,
        reo_all_idx
    ).to(device)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹å‚æ•°: {total_params:,}\n")
    
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=args.learning_rate,
        weight_decay=args.weight_decay
    )
    
    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(
        optimizer,
        milestones=[1, 35, 40],
        gamma=0.5,
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("=" * 80)
    print("å¼€å§‹è®­ç»ƒ")
    print("=" * 80)
    print(f"Batch Size: {args.batch_size}")
    print(f"Max Epochs: {args.max_epoch}")
    print("=" * 80)
    print()
    
    min_val_loss = float('inf')
    best_epoch = 0
    num_train = trainX.shape[0]
    
    for epoch in range(1, args.max_epoch + 1):
        epoch_start_time = time.time()
        model.train()
        train_loss_sum = 0.0
        batch_count = 0
        
        # æ‰“ä¹±è®­ç»ƒæ•°æ®
        indices = np.random.permutation(num_train)
        trainX = trainX[indices]
        trainY = trainY[indices]
        trainXTE = trainXTE[indices]
        
        num_batch = math.ceil(num_train / args.batch_size)
        
        pbar = tqdm(range(num_batch), desc=f"Epoch {epoch}/{args.max_epoch}")
        
        for batch_idx in pbar:
            start_idx = batch_idx * args.batch_size
            end_idx = min(num_train, (batch_idx + 1) * args.batch_size)

            X = trainX[start_idx:end_idx]
            Y = trainY[start_idx:end_idx]
            TE = torch.from_numpy(trainXTE[start_idx:end_idx]).to(device)
            NormX = torch.from_numpy((X - mean) / std).float().to(device)
            Y_tensor = torch.from_numpy(Y).float().to(device)
            
            optimizer.zero_grad()
            y_hat = model(NormX, TE)
            loss = _compute_loss(Y_tensor, y_hat * std + mean)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)
            optimizer.step()
            
            train_loss_sum += loss.cpu().item()
            batch_count += 1
            
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        avg_train_loss = train_loss_sum / batch_count
        
        # éªŒè¯
        maes, rmses, mapes = validate(
            model, valX, valY, valXTE, mean, std, device, args.batch_size
        )
        
        val_mae = maes[-1]
        
        print(f"\nEpoch {epoch}:")
        print(f"  è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}")
        print(f"  éªŒè¯ MAE: {val_mae:.4f}")
        print(f"  ç”¨æ—¶: {time.time() - epoch_start_time:.1f}s")
        
        log_string(log, f"Epoch {epoch}: Train Loss={avg_train_loss:.4f}, Val MAE={val_mae:.4f}")
        
        lr_scheduler.step()
        
        if val_mae < min_val_loss:
            min_val_loss = val_mae
            best_epoch = epoch
            torch.save(model.state_dict(), args.model_file)
            print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹")
        print()
    
    # æµ‹è¯•
    print("=" * 80)
    print("æµ‹è¯•é›†è¯„ä¼°")
    print("=" * 80)
    
    model.load_state_dict(torch.load(args.model_file))
    maes, rmses, mapes = validate(
        model, testX, testY, testXTE, mean, std, device, args.batch_size
    )
    
    print(f"\næœ€ç»ˆæµ‹è¯•ç»“æœ:")
    print(f"  MAE:  {maes[-1]:.4f}")
    print(f"  RMSE: {rmses[-1]:.4f}")
    print(f"  MAPE: {mapes[-1]:.4f}")
    
    log.close()
    
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³ Epoch: {best_epoch}")
    print(f"æ¨¡å‹: {args.model_file}")
    print(f"æ—¥å¿—: {args.log_file}")


if __name__ == '__main__':
    main()
